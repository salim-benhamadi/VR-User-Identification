{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Training \n",
    "\n",
    "## 3.1. Movement Data\n",
    "Starting first with trying to predict User using statistical features of movement data, and testing different time intervels and it's effect on the accuracy of the results\n",
    "### 3.1.1. Using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# importing Machine Learning Models\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "# import numpy for math calculations\n",
    "import numpy as np\n",
    "\n",
    "# import pandas for data (csv) manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# import gc to collect garbage\n",
    "import gc\n",
    "\n",
    "# import matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('fivethirtyeight') \n",
    "%matplotlib inline\n",
    "\n",
    "# import os for system operations\n",
    "import os\n",
    "\n",
    "# import sklearn for machine learning modelling and preprocessing\n",
    "import sklearn\n",
    "\n",
    "# importing Machine Learning Models\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier,AdaBoostClassifier,BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "\n",
    "# importing from sklearn the evaluation metrics for classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# importing from sklearn model selection \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold, learning_curve,StratifiedShuffleSplit\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# import tqdm to show a smart progress meter\n",
    "from tqdm.notebook import trange,tqdm\n",
    "\n",
    "# import warnings to hide the unnessairy warniings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(df):\n",
    "    \"\"\"\n",
    "    Builds the dataset to plot the feature importance.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Sort features according to importance\n",
    "    df = df.sort_values(['Importance'],ascending=False).reset_index()\n",
    "    \n",
    "    # drop the old index to avoid confusion\n",
    "    df = df.drop(['index'],axis=1)\n",
    "    \n",
    "    # Make a horizontal bar chart of feature importances\n",
    "    plt.figure(figsize = (10, 9))\n",
    "    ax = plt.subplot()\n",
    "    \n",
    "    # Need to reverse the index to plot most important on top\n",
    "    ax.barh(list(reversed(list(df.index[:30]))), \n",
    "            df['Importance'].head(30), \n",
    "            align = 'center', edgecolor = 'k')\n",
    "    \n",
    "    # Set the yticks and labels\n",
    "    ax.set_yticks(list(reversed(list(df.index[:30]))))\n",
    "    ax.set_yticklabels(df['Feature'].head(30))\n",
    "    \n",
    "    plt.xlabel(\"Normalized feature importance\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    \n",
    "    plt.show()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [['SVC',SVC(kernel=\"rbf\", C=0.025, probability=True, random_state=SEED)],\n",
    "               ['ExtraTreesClassifier', ExtraTreesClassifier(random_state=SEED)],\n",
    "              [\"LinearDiscriminantAnalysis\", LinearDiscriminantAnalysis()],\n",
    "              ['DecisionTreeClassifier',DecisionTreeClassifier(random_state=SEED)],\n",
    "              ['KNeighborsClassifier', KNeighborsClassifier()],\n",
    "              ['RandomForestClassifier', RandomForestClassifier(random_state=SEED)],\n",
    "              ['MLPClassifier',MLPClassifier(random_state=SEED)],\n",
    "              ['AdaBoostClassifier',AdaBoostClassifier(random_state=SEED)],\n",
    "              ['NuSVC',NuSVC(probability=True,random_state=SEED)],\n",
    "              ['GaussianNB', GaussianNB()],\n",
    "              ['QuadraticDiscriminantAnalysis',QuadraticDiscriminantAnalysis()],\n",
    "              ['LogisticRegression', LogisticRegression(random_state=SEED)],\n",
    "              ['XGBClassifier', XGBClassifier(random_state=SEED)],\n",
    "              ['BernoulliNB', BernoulliNB()],\n",
    "              ['MultinomialNB', MultinomialNB()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearnex import patch_sklearn, config_context\n",
    "patch_sklearn()\n",
    "\n",
    "def evaluate_classifiers(classifiers):\n",
    "    models = []\n",
    "    Accuracy_set = pd.DataFrame(index=None, columns=['Model','Accuracy(Train)','Accuracy(Test)','F1(Train)','F1(Test)', 'Precision(Train)','Precision(Test)', 'Recall(Train)','Recall(Test)', 'Log_loss(Train)','Log_loss(Test)'])\n",
    "    for i in tqdm(range(len(classifiers))):\n",
    "        name = classifiers[i][0]\n",
    "        model = classifiers[i][1]\n",
    "\n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "        y_train_predicted = model.predict(X_train)\n",
    "        y_test_predicited = model.predict(X_test)\n",
    "\n",
    "        accuracy_train = accuracy_score(y_train, y_train_predicted)\n",
    "        accuracy_test = accuracy_score(y_test, y_test_predicited)\n",
    "\n",
    "        f1_Score_train = f1_score(y_train, y_train_predicted,average='micro')\n",
    "        f1_Score_test = f1_score(y_test, y_test_predicited,average='micro')\n",
    "\n",
    "        precision_score_train = precision_score(y_train, y_train_predicted,average='micro')\n",
    "        precision_score_test = precision_score(y_test, y_test_predicited,average='micro')\n",
    "\n",
    "        recall_score_train = recall_score(y_train, y_train_predicted,average='micro')\n",
    "        recall_score_test = recall_score(y_test, y_test_predicited,average='micro')\n",
    "\n",
    "        log_loss_train = log_loss(y_train, model.predict_proba(X_train))\n",
    "        log_loss_test = log_loss(y_test, model.predict_proba(X_test))\n",
    "\n",
    "        # store the models\n",
    "        models.append((name,accuracy_test,model))\n",
    "\n",
    "        Accuracy_set = Accuracy_set.append(pd.Series({'Model':name, 'Accuracy(Train)':accuracy_train,'Accuracy(Test)':accuracy_test,'F1(Train)':f1_Score_train,'F1(Test)':f1_Score_test,'Precision(Train)':precision_score_train,'Precision(Test)':precision_score_test,'Recall(Train)':recall_score_train,'Recall(Test)':recall_score_test,'Log_loss(Train)':log_loss_train,'Log_loss(Test)':log_loss_test}),ignore_index=True )\n",
    "    return Accuracy_set, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_set, models = evaluate_classifiers(classifiers)\n",
    "Accuracy_set.sort_values(by='Accuracy(Test)').style.background_gradient(cmap= plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "g = sns.barplot(1,0, data = pd.DataFrame(models), palette=\"coolwarm\",orient = \"h\")\n",
    "g.set_xlabel(\"Mean Accuracy\")\n",
    "g = g.set_title(\"Cross validation scores\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
